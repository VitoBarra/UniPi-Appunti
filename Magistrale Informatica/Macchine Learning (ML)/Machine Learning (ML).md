---
Parent MOC: "[[Magistrale Informatica IA MOC]]"
tags:
  - MOC
  - ML
---
# Machine Learning ML

## Course MOC  ðŸ“’
1. [[Concetti generali del Machine Learning]]
	1. [[Algoritmi di Machine Learning]]
		1. [[Algoritmi di learning supervisionato]]
		2. [[Algoritmi di learning NON supervisionato]]
		3. [[Algoritmi di learning semi-supervisionato]]
	2. [[Rappresentazione simbolica e distribuita dei concetti]]
	3. [[Modelli di Machine Learning]]
		1. [[Modelli Parametrici]]
			1. [[Reti Neurali (NN)]]
		2. [[Modelli di machine learning NON parametrici]]
			1. [[Modelli Instance-Based]]
2. Teoria
	1. [[Bias-Variance Decomposition]]
	2. [[Overfitting e Underfitting]]
	3. [[Statistical Learning Theory (SLT)]]
		1. [[PAC learning]]
	4. [[Validation e Test di una modello di ML]]
		1. [[Tecniche per la ricerca degli iperparametri]]
		2. [[Validazione Hold-Out]]
		3. [[K-Fold Cross Validation]]
		4. [[Double cross validation (Nested k-fold cross validation)]]
	5. [[Linear Basis Expansion (LBE)]]
	6. [[Tecnica di ottimizzazione Gradient Descent]]
	7. [[Teorema di approssimazione universale]]
	8. [[Teorema di copertura (Cover Theorem)]]
	9. [[Teorema di Mercer]]
	10. [[UniPi-Appunti/Magistrale Informatica/Macchine Learning (ML)/Note/Deep Learning]]
	11. [[Curse of dimensionality e Curse of noise]]
3. [[Modelli lineari - Retta di regressione]]
    1. [[Modelli lineari con LMS]]
    	2. [[Linear Threshold Unit (LTU)]]
4. [[K-Nearest Neighbor (K-NN)]]
5. [[Support Vector Machine (SVM)]]
	1. [[Support Vector Machine per la regressione (SVR)]]
6. [[Ensemble Learning]]
	1. [[Bagging (bootsrap aggregating)]]
	2. [[Boosting]]
7. [[Rete di Percettroni]]
8. [[Reti neurali Feed-Forward (FF)]]
9. [[Back Propagation]]
10. [[Euristiche per il gli algoritmi di learning su reti neurali]]
	1. [[Reti neurali approccio costruttivo Cascade Correlation (NN-CC)]]
11. [[NN - Autoassociatore]]
	1. [[NN - Autoencoders]]
12. [[Funzioni di attivazione]]
	1. [[Funzione di attivazione - ReLu]]
	2. [[Funzione di attivazione - LeakyReLu]]
	3. [[Funzione di attivazione - ELU]]
	4. [[Funzione di attivazione - SoftPlus]]
	5. [[Funzione di attivazione - Sigmoide]]
	6. [[Funzione di attivazione - TanH]]
	7. [[Funzione di attivazione - SoftMax]]
13. Funzioni di loss
	1. [[Cross Entropy]]
14. [[Convolutional Neural Network  (CNN)]]
15. [[Input delay neural network (IDNN)]]
16. [[Recurrent Neural Network (RNN)]]
	1. [[RNN - Long Short-term Memory (LSTM)]]
	2. [[RNN - Gated recurrent unit (GRU)]] 
	3. [[RNN - Transformer]] 
17. [[Random Neural Network (RandNN)]]
18. [[RandRNN - Reservoir Computing]] 
	1. [[Reservoir Computing - Echo State Network (ESN)]] 
	2. [[Reservoir Computing - Liquid State Machine]] (extra)
	3. [[Reservoir Computing - BackPropagation Decorrelation]] (extra)
19. [[Recurrent neural network (RecNN)]]
20. [[Structural Domain Learning (SDL)]]
21. [[Data analysis -  Clustering]]
	1. [[K-Means]]
	2. [[Self organizing Map (SOM)]]


### Educational Material ðŸ§±
1. [[Simon Haykin - Neural Networks - 2ed.pdf]]
2. [[Simon Haykin - Neural Networks - 3ed.pdf]]




